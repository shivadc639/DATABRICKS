{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ef4045e-d6ae-49d0-a8fa-fc5c487cac6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Stream Customers data from cloud to Delta Lake\n",
    "#### 1. Read files from cloud storage using AutoLoader\n",
    "#### 2. Transform the dataframe to add following columns.\n",
    "- ##### Cloud file_path\n",
    "- ##### Ingestion_date \n",
    "#### 3. Write the transformed data stream to Delta Lake table.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46776fcf-0aaa-467e-be6c-a732718ae4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Read files from cloud storage using AutoLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c6e4b14-ef6b-416c-8461-5b1a301c92be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- ##### Autoloader supports schema evalution so schema for the tables neednot to be explicitly defined. \n",
    "- ##### `.format(cloudFiles)` Enables Autoloader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43139969-383c-4260-b1ba-c3d9bea95d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers_autoloader = (spark\n",
    "                        .readStream\n",
    "                        .format('cloudFiles')\n",
    "                        .option('cloudFiles.format', 'json')\n",
    "                        .option('cloudFiles.schemaLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_schema')\n",
    "                        .option('cloudFiles.inferColumnTypes', 'True')\n",
    "                        .load('/Volumes/gizmobox/landing/operations_volume/customers_autoloader/')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82fd4a61-100a-417f-a3aa-478b0435dcb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- ##### 1. `.option('cloudFiles.inferColumnTypes', 'True')` Enables automatic schema inference by autoloader.\n",
    "- ##### 2. `.option('cloudFiles.schemaLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_schema')` Defines the path where Schema is to be stored.\n",
    "- ##### `.option('cloudFiles.schemaHints, 'col1 datatype, col2 datatype, col3 datatype')` can be used to define the schema hints for the required columns if `.option('cloudFiles.inferColumnTypes', 'True')` misreads the schema datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18c0c47e-d56e-4597-917a-a6be823d366a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers_autoloader = (spark\n",
    "                        .readStream\n",
    "                        .format('cloudFiles')\n",
    "                        .option('cloudFiles.format', 'json')\n",
    "                        .option('cloudFiles.schemaLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_schema')\n",
    "                        .option('cloudFiles.inferColumnTypes', 'True')\n",
    "                        .option('cloudFiles.schemaHints', 'created_timestamp TIMESTAMP,customer_id INTEGER, date_of_birth DATE, member_since DATE')\n",
    "                        .load('/Volumes/gizmobox/landing/operations_volume/customers_autoloader/')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26f07b4f-37d3-4626-805e-c03d67d08f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### `.option('pathGlobFilter')` helps in ingesting only the required file pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49d96ca2-9c40-4285-90ec-7727b59753b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers_autoloader = (spark\n",
    "                        .readStream\n",
    "                        .format('cloudFiles')\n",
    "                        .option('cloudFiles.format', 'json')\n",
    "                        .option('cloudFiles.schemaLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_schema')\n",
    "                        .option('cloudFiles.inferColumnTypes', 'True')\n",
    "                        .option('cloudFiles.schemaHints', 'created_timestamp TIMESTAMP,customer_id INTEGER, date_of_birth DATE, member_since DATE')\n",
    "                        .option('pathGlobFilter', 'customers_2024_*.json')\n",
    "                        .load('/Volumes/gizmobox/landing/operations_volume/customers_autoloader/')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc2d94ba-23ba-40a9-b006-b83d46733419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- #### `.option('cloudFiles.schemaEvolutionMode','addNewColumns/rescue/failOnNewColumns/none')` determines the behaviour of stream when a new file with different schema is inserted to the ingestion path.\n",
    "\n",
    "- ####  `addNewColumns` is the default option when schema is not defined explicitly. When schema is defined explicitly `none` is the default.\n",
    "\n",
    "- #### `.option('mergeSchema', 'True')` should be added to writeStream query to merge the new schema change to the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46c5a9e0-f871-45e3-a2c6-a92a6b19660d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers_autoloader = (spark\n",
    "                        .readStream\n",
    "                        .format('cloudFiles')\n",
    "                        .option('cloudFiles.format', 'json')\n",
    "                        .option('cloudFiles.schemaLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_schema')\n",
    "                        .option('cloudFiles.inferColumnTypes', 'True')\n",
    "                        .option('cloudFiles.schemaHints', 'created_timestamp TIMESTAMP,customer_id INTEGER, date_of_birth DATE, member_since DATE')\n",
    "                        .option('pathGlobFilter', 'customers_2024_*.json')\n",
    "                        .option('cloudFiles.schemaEvolutionMode', 'addNewColumns')\n",
    "                        .load('/Volumes/gizmobox/landing/operations_volume/customers_autoloader/')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b14a71a8-3951-48f7-93d4-c1ccfc31595c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Transform the dataframe to add following columns.\n",
    "- #### Cloud file_path\n",
    "- #### Ingestion_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eed84df-7d90-4c54-ab1c-d445242368ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "df_customers_stream_autoloader_transformed = (df_customers_autoloader\n",
    "                                                    .withColumn('file_path', col('_metadata.file_path'))\n",
    "                                                    .withColumn('ingestion_date', current_timestamp())\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d3b1102-bf61-49f1-b143-1df3c673543f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3. Write the transformed data stream to Delta Lake table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b572549d-7037-4bf6-928e-c3772db4c8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_streaming_autloader_query = (df_customers_stream_autoloader_transformed\n",
    "                                      .writeStream\n",
    "                                      .format('delta')\n",
    "                                      .option('checkpointLocation', '/Volumes/gizmobox/landing/operations_volume/customers_autoloader/_autoloader_checkpoint')\n",
    "                                      .option('mergeSchema', 'True')\n",
    "                                      .toTable('gizmobox.bronze.customers_autoloader_stream')\n",
    "                            )\n",
    "display(customers_streaming_autloader_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bb9dfd6-e151-4327-92dc-64f87d5ff95f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766531086974}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql('Select * from gizmobox.bronze.customers_autoloader_stream'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0ae9536-952c-4fc4-8b6e-857e58c249fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- #### writeStream queries will not stop automatically. It has to be manually terminated. It can be manually terminated by clicking on `Terminate` icon in the query block or by using `.stop()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514ef903-335d-409c-a4ba-d42fe9ee8742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_streaming_autloader_query.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. Ingest Customers AutoLoader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
